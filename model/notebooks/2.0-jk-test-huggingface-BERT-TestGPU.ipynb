{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f9c260299c38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Huggingface36\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# The given stream is on a different device; have to restore the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# current_stream on that device on exit as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mdst_prev_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurrent_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Huggingface36\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_gencode_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;34mr\"\"\"Returns NVCC gencode flags this library were compiled with.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[0march_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_arch_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Huggingface36\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_cudart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudaError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mCudaError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ticket data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"../data/JIRA-Export-13.10.2022.xlsx\", engine=\"openpyxl\")\n",
    "df.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Beschreibung\", \"Benötigte Zeit\"]]\n",
    "df = df.rename(columns={\"Beschreibung\":\"x\", \"Benötigte Zeit\":\"y\"})\n",
    "df[\"y\"] = df[\"y\"].astype(str)\n",
    "df[\"x\"] = df[\"x\"].astype(str)\n",
    "df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Base Model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "BASE_MODEL = \"bert-base-german-cased\"\n",
    "#BASE_MODEL = \"bert-base-cased\"\n",
    "LEARNING_RATE = 2e-5\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16 # perhaps use 8 to 16\n",
    "EPOCHS = 20 # 20 -> use stop condition\n",
    "\n",
    "#id2label = #TODO: Define {0,1,2,.. : 1h,2h,4h,..} \n",
    "#label2id = #TODO: inverted id2label\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# classification:\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, id2label=id2label, label2id=label2id)\n",
    "\n",
    "# regression:\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input\n",
    "def token_preprocessor(df):\n",
    "    label = df[\"y\"] \n",
    "    df = tokenizer(df[\"x\"], padding=\"max_length\", max_length=256, truncation=True)\n",
    "    # classification:\n",
    "    # df[\"label\"] = label\n",
    "    # regression\n",
    "    df[\"label\"] = float(label)\n",
    "    #print(df)\n",
    "    return df\n",
    "    #return tokenizer(df[\"x\"], padding=\"max_length\", max_length=256, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.20, random_state=123)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df[\"X\"], df[\"y\"], test_size=0.20, random_state=123)\n",
    "\n",
    "ds = {\"train\": Dataset.from_dict(train), \"test\": Dataset.from_dict(test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22ff3ec206145b9b3d1f4f8329ee51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3543 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbfc5cd9af24454b2bcecdcf6bbc47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in ds:\n",
    "    ds[split] = ds[split].map(token_preprocessor, remove_columns=[\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 3543\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "     num_rows: 886\n",
       " })}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    \n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "    \n",
    "    # Compute accuracy \n",
    "    # Based on the fact that the rounded score = true score only if |single_squared_errors| < 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Training Params\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../trainoutput/\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    load_best_model_at_end=True,\n",
    "    weight_decay=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3543\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4440\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4342' max='4440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4342/4440 27:18:42 < 37:00, 0.04 it/s, Epoch 19.55/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>R2</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4102057472.000000</td>\n",
       "      <td>4102057472.000000</td>\n",
       "      <td>34806.929688</td>\n",
       "      <td>-0.419134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4101838848.000000</td>\n",
       "      <td>4101838848.000000</td>\n",
       "      <td>34803.785156</td>\n",
       "      <td>-0.419059</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3301905268.736000</td>\n",
       "      <td>4101632768.000000</td>\n",
       "      <td>4101632768.000000</td>\n",
       "      <td>34800.828125</td>\n",
       "      <td>-0.418987</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3301905268.736000</td>\n",
       "      <td>4101438208.000000</td>\n",
       "      <td>4101438208.000000</td>\n",
       "      <td>34798.035156</td>\n",
       "      <td>-0.418920</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3298897166.336000</td>\n",
       "      <td>4101255680.000000</td>\n",
       "      <td>4101255424.000000</td>\n",
       "      <td>34795.410156</td>\n",
       "      <td>-0.418857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3298897166.336000</td>\n",
       "      <td>4101084928.000000</td>\n",
       "      <td>4101084416.000000</td>\n",
       "      <td>34792.953125</td>\n",
       "      <td>-0.418798</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3171325050.880000</td>\n",
       "      <td>4100925696.000000</td>\n",
       "      <td>4100925440.000000</td>\n",
       "      <td>34790.664062</td>\n",
       "      <td>-0.418743</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3171325050.880000</td>\n",
       "      <td>4100778240.000000</td>\n",
       "      <td>4100777984.000000</td>\n",
       "      <td>34788.542969</td>\n",
       "      <td>-0.418692</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3171325050.880000</td>\n",
       "      <td>4100642560.000000</td>\n",
       "      <td>4100642816.000000</td>\n",
       "      <td>34786.601562</td>\n",
       "      <td>-0.418645</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3294076862.464000</td>\n",
       "      <td>4100519168.000000</td>\n",
       "      <td>4100519168.000000</td>\n",
       "      <td>34784.820312</td>\n",
       "      <td>-0.418602</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3294076862.464000</td>\n",
       "      <td>4100407296.000000</td>\n",
       "      <td>4100407296.000000</td>\n",
       "      <td>34783.222656</td>\n",
       "      <td>-0.418563</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3264412123.136000</td>\n",
       "      <td>4100307200.000000</td>\n",
       "      <td>4100306944.000000</td>\n",
       "      <td>34781.777344</td>\n",
       "      <td>-0.418529</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3264412123.136000</td>\n",
       "      <td>4100218880.000000</td>\n",
       "      <td>4100218880.000000</td>\n",
       "      <td>34780.503906</td>\n",
       "      <td>-0.418498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3200956235.776000</td>\n",
       "      <td>4100142848.000000</td>\n",
       "      <td>4100142592.000000</td>\n",
       "      <td>34779.410156</td>\n",
       "      <td>-0.418472</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3200956235.776000</td>\n",
       "      <td>4100077312.000000</td>\n",
       "      <td>4100077824.000000</td>\n",
       "      <td>34778.472656</td>\n",
       "      <td>-0.418449</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3244391923.712000</td>\n",
       "      <td>4100024576.000000</td>\n",
       "      <td>4100024576.000000</td>\n",
       "      <td>34777.714844</td>\n",
       "      <td>-0.418431</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3244391923.712000</td>\n",
       "      <td>4099983360.000000</td>\n",
       "      <td>4099983616.000000</td>\n",
       "      <td>34777.125000</td>\n",
       "      <td>-0.418417</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3244391923.712000</td>\n",
       "      <td>4099954176.000000</td>\n",
       "      <td>4099953408.000000</td>\n",
       "      <td>34776.699219</td>\n",
       "      <td>-0.418406</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3346136039.424000</td>\n",
       "      <td>4099936256.000000</td>\n",
       "      <td>4099936000.000000</td>\n",
       "      <td>34776.445312</td>\n",
       "      <td>-0.418400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-222\n",
      "Configuration saved in ../trainoutput/checkpoint-222\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-222\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-444\n",
      "Configuration saved in ../trainoutput/checkpoint-444\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-444\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-886] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-666\n",
      "Configuration saved in ../trainoutput/checkpoint-666\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-666\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-444] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-888\n",
      "Configuration saved in ../trainoutput/checkpoint-888\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-888\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-666] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-1110\n",
      "Configuration saved in ../trainoutput/checkpoint-1110\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-1110\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-888] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-1332\n",
      "Configuration saved in ../trainoutput/checkpoint-1332\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-1332\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-1110] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-1554\n",
      "Configuration saved in ../trainoutput/checkpoint-1554\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-1554\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-1332] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-1776\n",
      "Configuration saved in ../trainoutput/checkpoint-1776\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-1776\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-1554] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-1998\n",
      "Configuration saved in ../trainoutput/checkpoint-1998\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-1998\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-1776] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-2220\n",
      "Configuration saved in ../trainoutput/checkpoint-2220\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-2220\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-1998] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-2442\n",
      "Configuration saved in ../trainoutput/checkpoint-2442\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-2442\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-2220] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-2664\n",
      "Configuration saved in ../trainoutput/checkpoint-2664\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-2664\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-2442] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-2886\n",
      "Configuration saved in ../trainoutput/checkpoint-2886\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-2886\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-2664] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-3108\n",
      "Configuration saved in ../trainoutput/checkpoint-3108\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-3108\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-2886] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-3330\n",
      "Configuration saved in ../trainoutput/checkpoint-3330\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-3330\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-3108] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-3552\n",
      "Configuration saved in ../trainoutput/checkpoint-3552\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-3552\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-3330] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-3774\n",
      "Configuration saved in ../trainoutput/checkpoint-3774\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-3774\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-3552] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-3996\n",
      "Configuration saved in ../trainoutput/checkpoint-3996\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-3996\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-3774] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 886\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../trainoutput/checkpoint-4218\n",
      "Configuration saved in ../trainoutput/checkpoint-4218\\config.json\n",
      "Model weights saved in ../trainoutput/checkpoint-4218\\pytorch_model.bin\n",
      "Deleting older checkpoint [..\\trainoutput\\checkpoint-3996] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class RegressionTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0][:, 0]\n",
    "        loss = torch.nn.functional.mse_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "trainer = RegressionTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    compute_metrics=compute_metrics_for_regression\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string1 = \"Das Icon muss ausgewechselt werden! Lorem ipsum dolor sit amet, dnmsakd \\n hahah IT User, Oberfläche\"\n",
    "test_string2 = \"\"\"IST: \n",
    "Wird im EHB \"Stichprobenbildung ohne Ergebniserfassung\" im Abschnitt \"Stichprobenbildung vollstationär ohne Ergebniserfassung\" \"Regelprüfung\" markiert, dann ist im Abschnitt \"Ergänzende Stichprobe bei Anlass- /Wiederholungsprüfung\" über den Button \"Weiteres\" eine weitere Person erfassbar. \n",
    "\n",
    "Soll: \n",
    "Im Abschnitt \"Ergänzende Stichprobe bei Anlass- /Wiederholungsprüfung\" soll ausschließlich eine Person erfassbar sein, wenn in Abschnitt \"Stichprobenbildung vollstationär ohne Ergebniserfassung\" \"Anlass/Wiederholungsprüfung\" markiert wurde \n",
    "\"\"\"\n",
    "test_string3 = \"Frage 3.5 (E Frage) wurde im EHB Einrichtung ausgefüllt und \\\"Empfehlung geben\\\" angekreuzt \\nIm Produktergebnis wird Frage 3.5 nicht in die Tabelle(Empfehlungen zur Beseitigung von Qualitätsdefiziten) aufgenommen\"\n",
    "some_strings = [test_string1, test_string2, test_string3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer(some_strings, padding=\"max_length\", max_length=256, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.531217575073242, 18.532835006713867, 18.53243637084961]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**encoded).logits.reshape(-1).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
